{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizawang/PCL/blob/main/pcl_linearmodel_with_augmenteddata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUVCRyowC8GV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFftAvRW1kmo",
        "outputId": "28babaf5-8478-40a1-a68c-53aa4575e23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmmCq8RmRxZV",
        "outputId": "e7243279-0154-4d4e-d8d5-f2586d0725f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PCL\n",
            "\u001b[0m\u001b[01;34m10-langs-subtask1_all\u001b[0m/            raw.pickle\n",
            "5nn_predictions.csv               README.txt\n",
            "\u001b[01;34mbacktranslation_subtask2\u001b[0m/         rebuilddata.py\n",
            "data1                             \u001b[01;34mref\u001b[0m/\n",
            "data1_augmented.csv               \u001b[01;34mres\u001b[0m/\n",
            "data1_aug.pickle                  sentiment_scoring.py\n",
            "data1.pickle                      task4_test.tsv\n",
            "data2.pickle                      ten-langs-regex-cleaned-binary-label.csv\n",
            "\u001b[01;34mDeepMoji\u001b[0m/                         \u001b[01;34mthePoorerTheMerrier\u001b[0m/\n",
            "dev_semeval_parids-labels.csv     tptm.csv\n",
            "dontpatronizeme_categories.tsv    train_semeval_parids-labels.csv\n",
            "dontpatronizeme_pcl.tsv           trn_5nn_predictions.csv\n",
            "dont_patronize_me.py              trndf1.csv\n",
            "emoji_feature_vectors_trn_x1.csv  trndf2.csv\n",
            "emoji_feature_vectors_tst_x1.csv  trn_encoded_with_senti_df1\n",
            "evaluation.py                     trn_x1_augmented\n",
            "model_graph.png                   trn_x1_original\n",
            "\u001b[01;34mmodelsForStack\u001b[0m/                   tstdf1.csv\n",
            "pcl.ipynb                         tstdf2.csv\n",
            "pcl-task1-augment-revised.ipynb   tst_final.pickle\n",
            "pcl-task2-augment.ipynb           tst_x1_original\n",
            "\u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/PCL/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "687DCSg6hJwQ"
      },
      "source": [
        "# This is for subtask 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX8GCzPGRqAq",
        "outputId": "24527f14-cba0-413c-85ab-d899826f28d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "from DeepMoji.deepmoji.attlayer import AttentionWeightedAverage\n",
        "from DeepMoji import main_emoji as emoji\n",
        "from dont_patronize_me import DontPatronizeMe as dpm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn import svm\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQpH1Db30S8F",
        "outputId": "dc90c059-8796-4492-809d-53786e3d28fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map of label to numerical label:\n",
            "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n"
          ]
        }
      ],
      "source": [
        "trn_file1 = \"dontpatronizeme_pcl.tsv\"\n",
        "trn_file2 = \"dontpatronizeme_categories.tsv\"\n",
        "tst_path = \"task4_test.tsv\"\n",
        "dpm_o = dpm('.', tst_path)\n",
        "dpm_o.load_task1()\n",
        "dpm_o.load_task2()\n",
        "dpm_o.load_test()\n",
        "data1 = dpm_o.train_task1_df\n",
        "data2 = dpm_o.train_task2_df\n",
        "data_tst = dpm_o.test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSu_pjilUL4Y"
      },
      "outputs": [],
      "source": [
        "# the final test set\n",
        "data1_tst = np.array(data_tst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW-cJqxMURjZ",
        "outputId": "ef3d0dff-2584-496f-c597-a8243ea27fb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        talking to the media after arriving at Islamab...\n",
              "1        \"\"\"\" world record guinness of 540 pounds of 7 ...\n",
              "2        \" The second dear memory I cherished was the d...\n",
              "3        \"\"\"\" today 's decision holds and affirms Ameri...\n",
              "4        Leaving his prepared notes , Francis shared hi...\n",
              "                               ...                        \n",
              "19400    this helps to explain why many white working-c...\n",
              "19401    The fate of nearly 790,000 undocumented young ...\n",
              "19402    \"\" brixton music group recognizes that the sea...\n",
              "19403    the seasiders crashed to a nine-shot defeat - ...\n",
              "19404    The theme 'marche for our lives ' , the demons...\n",
              "Name: text, Length: 19405, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## this data1 is augmented\n",
        "data1_aug = pd.read_csv(\"data1_augmented.csv\", encoding=\"utf-8\")\n",
        "data1_aug.dropna(inplace=True)\n",
        "trn_x1_all = data1_aug['text']\n",
        "trn_txt_all = data1_aug[['text']]\n",
        "trn_y1_all = data1_aug['label']\n",
        "trn_x1_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nieAMDjGeofU",
        "outputId": "30f8e89b-b473-49f8-a21a-4add0f1bdf0c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nlen([l for l in data1[\"label\"] if l == 1])\\ndata1_neg = data1[data1[\"label\"]==0]\\ndata1_neg = data1_neg[[\"text\", \"label\"]]\\ndata1_neg\\n'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "len([l for l in data1[\"label\"] if l == 1])\n",
        "data1_neg = data1[data1[\"label\"]==0]\n",
        "data1_neg = data1_neg[[\"text\", \"label\"]]\n",
        "data1_neg\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "HneITAi7kW_K",
        "outputId": "3978c54f-935a-42fa-df45-9fab1ae9fb02"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nlang_list = [\\'sv\\', \\'ru\\', \\'pt\\',\\'nl\\', \\'it\\', \\'fr\\', \\'fi\\', \\'es\\', \\'de\\', \\'cs\\']\\ndata1_pos = None\\nfor lan in lang_list:\\n  filepath = \"10-langs-subtask1_all/%s.csv\" % (lan)\\n  text = pd.read_csv(filepath, encoding=\"utf-8\")\\n  text.columns = [\"index\", \"text\"]\\n  label = pd.DataFrame(np.ones(shape=(len(text),), dtype=np.int8))\\n  df = pd.concat([text[\"text\"], label], axis = 1)\\n  df.columns = [\"text\", \"label\"]\\n  data1_pos = pd.concat([data1_pos, df], axis=0)\\n\\ndata1_augmented = pd.concat([data1_neg, data1_pos], axis=0) #row 7816 has empty text\\ndata1_augmented = data1_augmented[data1_augmented[\"text\"] != \"\"]\\ndata1_augmented = data1_augmented.sample(frac=1) #shuffle rows for the new combined data\\ndata1_augmented.to_csv(\"data1_augmented.csv\", encoding=\"utf-8\")\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "lang_list = ['sv', 'ru', 'pt','nl', 'it', 'fr', 'fi', 'es', 'de', 'cs']\n",
        "data1_pos = None\n",
        "for lan in lang_list:\n",
        "  filepath = \"10-langs-subtask1_all/%s.csv\" % (lan)\n",
        "  text = pd.read_csv(filepath, encoding=\"utf-8\")\n",
        "  text.columns = [\"index\", \"text\"]\n",
        "  label = pd.DataFrame(np.ones(shape=(len(text),), dtype=np.int8))\n",
        "  df = pd.concat([text[\"text\"], label], axis = 1)\n",
        "  df.columns = [\"text\", \"label\"]\n",
        "  data1_pos = pd.concat([data1_pos, df], axis=0)\n",
        "\n",
        "data1_augmented = pd.concat([data1_neg, data1_pos], axis=0) #row 7816 has empty text\n",
        "data1_augmented = data1_augmented[data1_augmented[\"text\"] != \"\"]\n",
        "data1_augmented = data1_augmented.sample(frac=1) #shuffle rows for the new combined data\n",
        "data1_augmented.to_csv(\"data1_augmented.csv\", encoding=\"utf-8\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DVwQ1IWm-Ju0"
      },
      "outputs": [],
      "source": [
        "data1 = data1[data1[\"text\"] != \"\"] #remove the empty text row 8639 with label 0\n",
        "for i, s in enumerate(data1[\"text\"]):\n",
        "  if s==\"\":\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ah-fx6ias1"
      },
      "source": [
        "# Dump data1 and data2 into pickle files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPSO4Rk1Hk6J"
      },
      "outputs": [],
      "source": [
        "with open(\"data2.pickle\", \"wb\") as f:\n",
        "  pickle.dump(data2, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPigZd3rQi2V"
      },
      "outputs": [],
      "source": [
        "with open(\"data1.pickle\", \"wb\") as fi:\n",
        "  pickle.dump(data1, fi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1kfJ3bwiw4_"
      },
      "source": [
        "# Get test set from original and training set from augmented data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzHAcJsn0J9x",
        "outputId": "e4418b89-7884-4653-cadc-3b71a4d68cf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4988     In fact , romance by far out-produces and out-...\n",
              "3053     In the past , Dorel has had moments of brillia...\n",
              "1984     A man who reached out to a community Facebook ...\n",
              "3547     Other westerners who met similar fate to Foley...\n",
              "4891     \"The home affairs department must explain why ...\n",
              "                               ...                        \n",
              "7193     Morris , who is blind , made the call in the S...\n",
              "8843     He said they are not always able to transfer m...\n",
              "6110     \"\"\" The broad part of officials and the masses...\n",
              "5848     It seems some Chinese immigrants come across a...\n",
              "10172    \"Meanwhile \"\" throughout this island , the hig...\n",
              "Name: text, Length: 2094, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "## get test set from the origninal dataset\n",
        "x1, y1 = data1[[\"text\"]], data1[\"label\"]\n",
        "_, tst_x1, _, tst_y1 = train_test_split(x1, y1, test_size=0.2, random_state=36)\n",
        "tst_txt_df = tst_x1\n",
        "tst_x1 = tst_x1['text']\n",
        "tst_x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "92ujoYtnZmK_",
        "outputId": "421d914a-55fe-4492-ada9-7fc43e020f7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d887970-abce-46b2-907d-c093bc3dd414\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6262</th>\n",
              "      <td>it was a tridional n leage budget . pro-elite ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9499</th>\n",
              "      <td>In their tweet , Reham stressed how a \" real l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>the letter came as the country grapples with a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9188</th>\n",
              "      <td>The Word of God is truth that 's life and able...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14445</th>\n",
              "      <td>Under the pretext of \"\" to know how the other ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5884</th>\n",
              "      <td>new york ( afp ) - the number of homeless scho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12889</th>\n",
              "      <td>But this can be devastating for disabled and e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4224</th>\n",
              "      <td>the bank group 's support focused on major tra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>When travelling through different communities ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7578</th>\n",
              "      <td>\"\"\" for each patient that the university hospi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15155 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d887970-abce-46b2-907d-c093bc3dd414')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d887970-abce-46b2-907d-c093bc3dd414 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d887970-abce-46b2-907d-c093bc3dd414');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  label\n",
              "6262   it was a tridional n leage budget . pro-elite ...      0\n",
              "9499   In their tweet , Reham stressed how a \" real l...      1\n",
              "1001   the letter came as the country grapples with a...      0\n",
              "9188   The Word of God is truth that 's life and able...      1\n",
              "14445  Under the pretext of \"\" to know how the other ...      1\n",
              "...                                                  ...    ...\n",
              "5884   new york ( afp ) - the number of homeless scho...      0\n",
              "12889  But this can be devastating for disabled and e...      1\n",
              "4224   the bank group 's support focused on major tra...      0\n",
              "8670   When travelling through different communities ...      1\n",
              "7578   \"\"\" for each patient that the university hospi...      0\n",
              "\n",
              "[15155 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## get the training set from the augmented dataset\n",
        "trndf1 = pd.read_csv(\"ten-langs-regex-cleaned-binary-label.csv\", encoding=\"utf-8\")\n",
        "trndf1 = trndf1.dropna() #drop the nan sentence on 733 row\n",
        "trndf1 = trndf1.sample(frac=1)\n",
        "trndf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GA2xtAW8HBOJ",
        "outputId": "a9fbfb9b-b415-422d-9cb4-511d718455bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ec36ed7d-7a72-4f74-86d9-a1ba6acd3f01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6262</th>\n",
              "      <td>it was a tridional n leage budget . pro-elite ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9499</th>\n",
              "      <td>In their tweet , Reham stressed how a \" real l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>the letter came as the country grapples with a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9188</th>\n",
              "      <td>The Word of God is truth that 's life and able...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14445</th>\n",
              "      <td>Under the pretext of \"\" to know how the other ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5884</th>\n",
              "      <td>new york ( afp ) - the number of homeless scho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12889</th>\n",
              "      <td>But this can be devastating for disabled and e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4224</th>\n",
              "      <td>the bank group 's support focused on major tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>When travelling through different communities ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7578</th>\n",
              "      <td>\"\"\" for each patient that the university hospi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15155 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec36ed7d-7a72-4f74-86d9-a1ba6acd3f01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ec36ed7d-7a72-4f74-86d9-a1ba6acd3f01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ec36ed7d-7a72-4f74-86d9-a1ba6acd3f01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text\n",
              "6262   it was a tridional n leage budget . pro-elite ...\n",
              "9499   In their tweet , Reham stressed how a \" real l...\n",
              "1001   the letter came as the country grapples with a...\n",
              "9188   The Word of God is truth that 's life and able...\n",
              "14445  Under the pretext of \"\" to know how the other ...\n",
              "...                                                  ...\n",
              "5884   new york ( afp ) - the number of homeless scho...\n",
              "12889  But this can be devastating for disabled and e...\n",
              "4224   the bank group 's support focused on major tra...\n",
              "8670   When travelling through different communities ...\n",
              "7578   \"\"\" for each patient that the university hospi...\n",
              "\n",
              "[15155 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "trn_x1 = trndf1['text']\n",
        "trn_txt_df = trndf1[['text']]\n",
        "trn_y1 = trndf1[\"label\"]\n",
        "trn_txt_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pT029rq2px1f"
      },
      "outputs": [],
      "source": [
        "for i, t in enumerate(trn_x1): ## check if 733 of trn_x1 is still nan\n",
        "  if t is np.nan:\n",
        "    print(i, t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJKpI2sO2VLp"
      },
      "outputs": [],
      "source": [
        "#trn_x1.to_csv(\"trn_x1_augmented\", encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLMlWMBwfI8E"
      },
      "source": [
        "* **Add** both word and charactar ngrams using **TF-IDF** vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c6F7jkBoU0iq"
      },
      "outputs": [],
      "source": [
        "def encoding(trn_x, tst_x=None, ngram = (1, 3), analyzer = \"word\", lowercase=True):\n",
        "  vectorizer = TfidfVectorizer(strip_accents=\"unicode\", stop_words=\"english\", lowercase=lowercase,\n",
        "                               analyzer=analyzer,ngram_range=ngram)\n",
        "  trn_x_encoded = vectorizer.fit_transform(trn_x)\n",
        "  if tst_x is not None:\n",
        "    tst_x_encoded = vectorizer.transform(tst_x)\n",
        "  else:\n",
        "    tst_x_encoded = \"\"\n",
        "  return trn_x_encoded, tst_x_encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zfQ-FWR9JsE",
        "outputId": "20e5153b-f8fc-4346-faf9-a1e73f839ac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2094x454621 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 815699 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# slipted data\n",
        "trn_x_encoded_word, tst_x_encoded_word = encoding(trn_x1, tst_x1, lowercase=True)\n",
        "trn_x_encoded_char, tst_x_encoded_char = encoding(trn_x1, tst_x1, analyzer=\"char\", lowercase=True)\n",
        "trn_x_encoded1 = hstack((trn_x_encoded_word, trn_x_encoded_char))\n",
        "tst_x_encoded1 = hstack((tst_x_encoded_word, tst_x_encoded_char))\n",
        "tst_x_encoded1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuOgmhJXWY8K",
        "outputId": "1ad8124b-b075-4d5a-d2fc-6fe84789390b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3828x574844 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1481680 stored elements in COOrdinate format>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# data1_all augmented\n",
        "trn_x_encoded_word, tst_x_encoded_word = encoding(trn_x1_all, data1_tst, lowercase=True)\n",
        "trn_x_encoded_char, tst_x_encoded_char = encoding(trn_x1_all, data1_tst, analyzer=\"char\", lowercase=False)\n",
        "trn_x1_all_encoded = hstack((trn_x_encoded_word, trn_x_encoded_char))\n",
        "tst_x1_all_encoded = hstack((tst_x_encoded_word, tst_x_encoded_char))\n",
        "tst_x1_all_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xqJzWvcDO-d",
        "outputId": "792f4975-3368-4eaf-9f6d-ba3734836363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<15155x454621 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 6444530 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "trn_x_encoded1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdc6u083fz4c"
      },
      "source": [
        "### **Add** sentiment scores using ruled based pretrained model **VADER** or machine-learning pretrained model **Flair**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpqZcTZ7gAAa"
      },
      "outputs": [],
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install flair\n",
        "from sentiment_scoring import senti_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu7BdXgwXCSo",
        "outputId": "1d14c87b-23ad-4a58-bdac-7a29497979d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.021 ,  0.862 ,  0.117 ,  0.8403],\n",
              "       [ 0.114 ,  0.762 ,  0.124 ,  0.0516],\n",
              "       [ 0.    ,  1.    ,  0.    ,  0.    ],\n",
              "       ...,\n",
              "       [ 0.064 ,  0.725 ,  0.211 ,  0.7269],\n",
              "       [ 0.138 ,  0.813 ,  0.049 , -0.786 ],\n",
              "       [ 0.    ,  0.876 ,  0.124 ,  0.6597]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# splited trn\n",
        "sc_trn1 = np.array(senti_score(trn_x1, \"vader\"))\n",
        "sc_tst1 = np.array(senti_score(tst_x1, \"vader\"))\n",
        "trn_x_encoded_with_senti = hstack((trn_x_encoded1, csr_matrix(sc_trn1)))\n",
        "tst_x_encoded_with_senti = hstack((tst_x_encoded1, csr_matrix(sc_tst1)))\n",
        "sc_trn1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGzbtWtmW3TN",
        "outputId": "3ffc1130-7dc6-4e90-dae6-804e98e322a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0.041, 0.73, 0.229, 0.8779], array([0.041 , 0.73  , 0.229 , 0.8779]))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# for all trn\n",
        "sc_trn1 = np.array(senti_score(trn_x1_all, \"vader\"))\n",
        "sc_tst1 = np.array(senti_score(data1_tst, \"vader\"))\n",
        "trn_x1_all_encoded_with_senti = hstack((trn_x1_all_encoded, csr_matrix(sc_trn1)))\n",
        "tst_x1_all_encoded_with_senti = hstack((tst_x1_all_encoded, csr_matrix(sc_tst1)))\n",
        "sc_trn1[0], csr_matrix(sc_trn1).toarray()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soWSrRzRZvPV",
        "outputId": "67e170bd-542f-4482-c169-f2f287265bfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<15155x457427 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 6489351 stored elements in COOrdinate format>,\n",
              " <2094x457427 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 836415 stored elements in COOrdinate format>,\n",
              " <15155x457431 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 6540562 stored elements in COOrdinate format>,\n",
              " <2094x457431 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 843399 stored elements in COOrdinate format>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "trn_x_encoded1, tst_x_encoded1, trn_x_encoded_with_senti, tst_x_encoded_with_senti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6__4XwXO44T"
      },
      "outputs": [],
      "source": [
        "## write into files so no need to run it again next time\n",
        "#trn_encoded_with_senti_df = pd.DataFrame.sparse.from_spmatrix(trn_x_encoded_with_senti)\n",
        "#tst_encoded_with_senti_df = pd.DataFrame.sparse.from_spmatrix(tst_x_encoded_with_senti)\n",
        "#trn_encoded_with_senti_df.to_csv(\"trn_encoded_with_senti_df1\")\n",
        "#tst_encoded_with_senti_df.to_csv(\"tst_encoded_with_senti_df1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g9jtzmDglL1"
      },
      "source": [
        "### Add **emoji prediction vectors** into the feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NxA-oouQE3vM"
      },
      "outputs": [],
      "source": [
        "max_len = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg8Tbhah_-hx",
        "outputId": "187eb9c5-550b-47b7-e9a0-d6fcd6bcc210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing using dictionary from /content/drive/MyDrive/PCL/DeepMoji/model/vocabulary.json\n",
            "Loading model from /content/drive/MyDrive/PCL/DeepMoji/model/deepmoji_weights.hdf5.\n",
            "Model: \"DeepMoji\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 80)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 80, 256)      12800000    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 80, 256)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " bi_lstm_0 (Bidirectional)      (None, 80, 1024)     3149824     ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " bi_lstm_1 (Bidirectional)      (None, 80, 1024)     6295552     ['bi_lstm_0[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 80, 2304)     0           ['bi_lstm_1[0][0]',              \n",
            "                                                                  'bi_lstm_0[0][0]',              \n",
            "                                                                  'activation[0][0]']             \n",
            "                                                                                                  \n",
            " attlayer (AttentionWeightedAve  (None, 2304)        2304        ['concatenate[0][0]']            \n",
            " rage)                                                                                            \n",
            "                                                                                                  \n",
            " softmax (Dense)                (None, 64)           147520      ['attlayer[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,395,200\n",
            "Trainable params: 22,395,200\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# produce prediction top5 from the function\n",
        "emoji_df1_trn = pd.DataFrame(emoji.emoji_prediction(trn_txt_df, maxlen=max_len))\n",
        "emoji_df1_trn = pd.DataFrame(emoji.emoji_prediction(trn_txt_df, maxlen=max_len))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_df1_tst = pd.DataFrame(emoji.emoji_prediction(tst_txt_df, maxlen=max_len))"
      ],
      "metadata": {
        "id": "QYZZpnqiMhou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "p-qu9qGg-1ZH"
      },
      "outputs": [],
      "source": [
        "emoji_trnx1 =  emoji_df1_trn[emoji_df1_trn.columns[-64:]]\n",
        "emoji_tstx1 = emoji_df1_tst[emoji_df1_tst.columns[-64:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Ls93dk6YLVLa",
        "outputId": "13d83aa4-0929-47db-ca33-2c96f54a659a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1caa6ede-c3fd-4187-ab58-e3c272163d56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003902</td>\n",
              "      <td>0.003144</td>\n",
              "      <td>0.002172</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>0.003493</td>\n",
              "      <td>0.008043</td>\n",
              "      <td>0.012574</td>\n",
              "      <td>0.011613</td>\n",
              "      <td>0.031763</td>\n",
              "      <td>0.002523</td>\n",
              "      <td>0.003797</td>\n",
              "      <td>0.018456</td>\n",
              "      <td>0.005843</td>\n",
              "      <td>0.030239</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.004263</td>\n",
              "      <td>0.012688</td>\n",
              "      <td>0.060602</td>\n",
              "      <td>0.007520</td>\n",
              "      <td>0.005722</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.115412</td>\n",
              "      <td>0.009594</td>\n",
              "      <td>0.004561</td>\n",
              "      <td>0.055930</td>\n",
              "      <td>0.011705</td>\n",
              "      <td>0.001510</td>\n",
              "      <td>0.013387</td>\n",
              "      <td>0.003931</td>\n",
              "      <td>0.002887</td>\n",
              "      <td>0.019267</td>\n",
              "      <td>0.013441</td>\n",
              "      <td>0.008764</td>\n",
              "      <td>0.056443</td>\n",
              "      <td>0.050920</td>\n",
              "      <td>0.008489</td>\n",
              "      <td>0.001837</td>\n",
              "      <td>0.004157</td>\n",
              "      <td>0.003714</td>\n",
              "      <td>0.002473</td>\n",
              "      <td>0.062329</td>\n",
              "      <td>0.012448</td>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.006939</td>\n",
              "      <td>0.010322</td>\n",
              "      <td>0.051934</td>\n",
              "      <td>0.034430</td>\n",
              "      <td>0.005517</td>\n",
              "      <td>0.002288</td>\n",
              "      <td>0.010055</td>\n",
              "      <td>0.005820</td>\n",
              "      <td>0.006401</td>\n",
              "      <td>0.016319</td>\n",
              "      <td>0.008308</td>\n",
              "      <td>0.006732</td>\n",
              "      <td>0.002145</td>\n",
              "      <td>0.009100</td>\n",
              "      <td>0.018133</td>\n",
              "      <td>0.018144</td>\n",
              "      <td>0.013681</td>\n",
              "      <td>0.039780</td>\n",
              "      <td>0.006316</td>\n",
              "      <td>0.011016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.013586</td>\n",
              "      <td>0.002661</td>\n",
              "      <td>0.003350</td>\n",
              "      <td>0.000904</td>\n",
              "      <td>0.012995</td>\n",
              "      <td>0.005279</td>\n",
              "      <td>0.006781</td>\n",
              "      <td>0.012200</td>\n",
              "      <td>0.001908</td>\n",
              "      <td>0.004423</td>\n",
              "      <td>0.013459</td>\n",
              "      <td>0.020442</td>\n",
              "      <td>0.002971</td>\n",
              "      <td>0.001383</td>\n",
              "      <td>0.001835</td>\n",
              "      <td>0.009044</td>\n",
              "      <td>0.004689</td>\n",
              "      <td>0.003047</td>\n",
              "      <td>0.024727</td>\n",
              "      <td>0.005838</td>\n",
              "      <td>0.020251</td>\n",
              "      <td>0.049059</td>\n",
              "      <td>0.001178</td>\n",
              "      <td>0.035783</td>\n",
              "      <td>0.033984</td>\n",
              "      <td>0.001785</td>\n",
              "      <td>0.030399</td>\n",
              "      <td>0.006533</td>\n",
              "      <td>0.003556</td>\n",
              "      <td>0.012235</td>\n",
              "      <td>0.006284</td>\n",
              "      <td>0.134241</td>\n",
              "      <td>0.030279</td>\n",
              "      <td>0.048326</td>\n",
              "      <td>0.009554</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.021561</td>\n",
              "      <td>0.004917</td>\n",
              "      <td>0.011859</td>\n",
              "      <td>0.013490</td>\n",
              "      <td>0.008717</td>\n",
              "      <td>0.006270</td>\n",
              "      <td>0.020887</td>\n",
              "      <td>0.010928</td>\n",
              "      <td>0.016790</td>\n",
              "      <td>0.036766</td>\n",
              "      <td>0.022239</td>\n",
              "      <td>0.002545</td>\n",
              "      <td>0.004012</td>\n",
              "      <td>0.008158</td>\n",
              "      <td>0.003557</td>\n",
              "      <td>0.022341</td>\n",
              "      <td>0.017795</td>\n",
              "      <td>0.011191</td>\n",
              "      <td>0.115052</td>\n",
              "      <td>0.004575</td>\n",
              "      <td>0.002411</td>\n",
              "      <td>0.011822</td>\n",
              "      <td>0.007022</td>\n",
              "      <td>0.006179</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>0.015914</td>\n",
              "      <td>0.003997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001358</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>0.002164</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.010033</td>\n",
              "      <td>0.003272</td>\n",
              "      <td>0.003894</td>\n",
              "      <td>0.005593</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.002546</td>\n",
              "      <td>0.001849</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>0.004989</td>\n",
              "      <td>0.001474</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.002544</td>\n",
              "      <td>0.003780</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>0.015351</td>\n",
              "      <td>0.003260</td>\n",
              "      <td>0.023862</td>\n",
              "      <td>0.035311</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>0.007628</td>\n",
              "      <td>0.023908</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.031092</td>\n",
              "      <td>0.002610</td>\n",
              "      <td>0.003424</td>\n",
              "      <td>0.005522</td>\n",
              "      <td>0.004240</td>\n",
              "      <td>0.299341</td>\n",
              "      <td>0.031532</td>\n",
              "      <td>0.036681</td>\n",
              "      <td>0.008280</td>\n",
              "      <td>0.000599</td>\n",
              "      <td>0.034092</td>\n",
              "      <td>0.001423</td>\n",
              "      <td>0.005277</td>\n",
              "      <td>0.009598</td>\n",
              "      <td>0.003416</td>\n",
              "      <td>0.017372</td>\n",
              "      <td>0.018462</td>\n",
              "      <td>0.033125</td>\n",
              "      <td>0.016628</td>\n",
              "      <td>0.022427</td>\n",
              "      <td>0.008393</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.002958</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>0.020868</td>\n",
              "      <td>0.005983</td>\n",
              "      <td>0.003698</td>\n",
              "      <td>0.132550</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>0.006710</td>\n",
              "      <td>0.014621</td>\n",
              "      <td>0.005408</td>\n",
              "      <td>0.001927</td>\n",
              "      <td>0.008010</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.001460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000907</td>\n",
              "      <td>0.006270</td>\n",
              "      <td>0.001169</td>\n",
              "      <td>0.002423</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>0.016971</td>\n",
              "      <td>0.002082</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.022318</td>\n",
              "      <td>0.000534</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>0.003538</td>\n",
              "      <td>0.007937</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.001077</td>\n",
              "      <td>0.003117</td>\n",
              "      <td>0.005327</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.007663</td>\n",
              "      <td>0.001208</td>\n",
              "      <td>0.117611</td>\n",
              "      <td>0.021668</td>\n",
              "      <td>0.000974</td>\n",
              "      <td>0.090199</td>\n",
              "      <td>0.011319</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.032096</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>0.007443</td>\n",
              "      <td>0.001389</td>\n",
              "      <td>0.132410</td>\n",
              "      <td>0.008047</td>\n",
              "      <td>0.078747</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>0.019441</td>\n",
              "      <td>0.001940</td>\n",
              "      <td>0.002919</td>\n",
              "      <td>0.008968</td>\n",
              "      <td>0.002832</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>0.012180</td>\n",
              "      <td>0.012739</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.107560</td>\n",
              "      <td>0.044752</td>\n",
              "      <td>0.000486</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>0.001760</td>\n",
              "      <td>0.009143</td>\n",
              "      <td>0.002720</td>\n",
              "      <td>0.002171</td>\n",
              "      <td>0.087614</td>\n",
              "      <td>0.002556</td>\n",
              "      <td>0.002667</td>\n",
              "      <td>0.010988</td>\n",
              "      <td>0.007887</td>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.013885</td>\n",
              "      <td>0.003157</td>\n",
              "      <td>0.002335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002756</td>\n",
              "      <td>0.012141</td>\n",
              "      <td>0.002344</td>\n",
              "      <td>0.003331</td>\n",
              "      <td>0.000675</td>\n",
              "      <td>0.013813</td>\n",
              "      <td>0.005703</td>\n",
              "      <td>0.005601</td>\n",
              "      <td>0.011995</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.003046</td>\n",
              "      <td>0.006338</td>\n",
              "      <td>0.006496</td>\n",
              "      <td>0.012066</td>\n",
              "      <td>0.001958</td>\n",
              "      <td>0.002757</td>\n",
              "      <td>0.006808</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.001505</td>\n",
              "      <td>0.020849</td>\n",
              "      <td>0.005074</td>\n",
              "      <td>0.045914</td>\n",
              "      <td>0.030738</td>\n",
              "      <td>0.001624</td>\n",
              "      <td>0.027136</td>\n",
              "      <td>0.030610</td>\n",
              "      <td>0.001415</td>\n",
              "      <td>0.022971</td>\n",
              "      <td>0.002307</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.018705</td>\n",
              "      <td>0.008074</td>\n",
              "      <td>0.125535</td>\n",
              "      <td>0.024634</td>\n",
              "      <td>0.043456</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.001043</td>\n",
              "      <td>0.028283</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>0.005097</td>\n",
              "      <td>0.020802</td>\n",
              "      <td>0.008330</td>\n",
              "      <td>0.013230</td>\n",
              "      <td>0.014753</td>\n",
              "      <td>0.037309</td>\n",
              "      <td>0.018985</td>\n",
              "      <td>0.049381</td>\n",
              "      <td>0.020670</td>\n",
              "      <td>0.001697</td>\n",
              "      <td>0.001956</td>\n",
              "      <td>0.012121</td>\n",
              "      <td>0.004628</td>\n",
              "      <td>0.015705</td>\n",
              "      <td>0.009923</td>\n",
              "      <td>0.010668</td>\n",
              "      <td>0.097144</td>\n",
              "      <td>0.013821</td>\n",
              "      <td>0.006033</td>\n",
              "      <td>0.026154</td>\n",
              "      <td>0.007259</td>\n",
              "      <td>0.003358</td>\n",
              "      <td>0.012590</td>\n",
              "      <td>0.010354</td>\n",
              "      <td>0.004409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15150</th>\n",
              "      <td>0.003458</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>0.002050</td>\n",
              "      <td>0.004504</td>\n",
              "      <td>0.001611</td>\n",
              "      <td>0.018252</td>\n",
              "      <td>0.009451</td>\n",
              "      <td>0.022500</td>\n",
              "      <td>0.021572</td>\n",
              "      <td>0.005467</td>\n",
              "      <td>0.009126</td>\n",
              "      <td>0.010067</td>\n",
              "      <td>0.006015</td>\n",
              "      <td>0.014631</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>0.011801</td>\n",
              "      <td>0.020654</td>\n",
              "      <td>0.012789</td>\n",
              "      <td>0.007399</td>\n",
              "      <td>0.004978</td>\n",
              "      <td>0.009404</td>\n",
              "      <td>0.058878</td>\n",
              "      <td>0.020302</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>0.041312</td>\n",
              "      <td>0.011554</td>\n",
              "      <td>0.002573</td>\n",
              "      <td>0.025373</td>\n",
              "      <td>0.003616</td>\n",
              "      <td>0.002775</td>\n",
              "      <td>0.029119</td>\n",
              "      <td>0.017634</td>\n",
              "      <td>0.008660</td>\n",
              "      <td>0.046545</td>\n",
              "      <td>0.042496</td>\n",
              "      <td>0.015981</td>\n",
              "      <td>0.002655</td>\n",
              "      <td>0.005565</td>\n",
              "      <td>0.003934</td>\n",
              "      <td>0.001818</td>\n",
              "      <td>0.013980</td>\n",
              "      <td>0.009776</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.059256</td>\n",
              "      <td>0.018743</td>\n",
              "      <td>0.049617</td>\n",
              "      <td>0.038806</td>\n",
              "      <td>0.003429</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.036353</td>\n",
              "      <td>0.004109</td>\n",
              "      <td>0.010119</td>\n",
              "      <td>0.024656</td>\n",
              "      <td>0.013992</td>\n",
              "      <td>0.007664</td>\n",
              "      <td>0.001887</td>\n",
              "      <td>0.026209</td>\n",
              "      <td>0.021205</td>\n",
              "      <td>0.018411</td>\n",
              "      <td>0.009747</td>\n",
              "      <td>0.028816</td>\n",
              "      <td>0.010205</td>\n",
              "      <td>0.026782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15151</th>\n",
              "      <td>0.010864</td>\n",
              "      <td>0.007201</td>\n",
              "      <td>0.008702</td>\n",
              "      <td>0.015379</td>\n",
              "      <td>0.002119</td>\n",
              "      <td>0.037926</td>\n",
              "      <td>0.010779</td>\n",
              "      <td>0.004920</td>\n",
              "      <td>0.005855</td>\n",
              "      <td>0.003646</td>\n",
              "      <td>0.006267</td>\n",
              "      <td>0.002994</td>\n",
              "      <td>0.026574</td>\n",
              "      <td>0.011232</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.004580</td>\n",
              "      <td>0.004367</td>\n",
              "      <td>0.020742</td>\n",
              "      <td>0.001568</td>\n",
              "      <td>0.011358</td>\n",
              "      <td>0.008802</td>\n",
              "      <td>0.046888</td>\n",
              "      <td>0.035637</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.004779</td>\n",
              "      <td>0.023115</td>\n",
              "      <td>0.002169</td>\n",
              "      <td>0.042274</td>\n",
              "      <td>0.005634</td>\n",
              "      <td>0.012052</td>\n",
              "      <td>0.006163</td>\n",
              "      <td>0.009177</td>\n",
              "      <td>0.029724</td>\n",
              "      <td>0.029705</td>\n",
              "      <td>0.140724</td>\n",
              "      <td>0.031909</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.014603</td>\n",
              "      <td>0.002180</td>\n",
              "      <td>0.011110</td>\n",
              "      <td>0.022160</td>\n",
              "      <td>0.015573</td>\n",
              "      <td>0.011530</td>\n",
              "      <td>0.017663</td>\n",
              "      <td>0.011140</td>\n",
              "      <td>0.030409</td>\n",
              "      <td>0.080824</td>\n",
              "      <td>0.006316</td>\n",
              "      <td>0.001296</td>\n",
              "      <td>0.004201</td>\n",
              "      <td>0.004285</td>\n",
              "      <td>0.011438</td>\n",
              "      <td>0.019104</td>\n",
              "      <td>0.008594</td>\n",
              "      <td>0.004275</td>\n",
              "      <td>0.021084</td>\n",
              "      <td>0.002492</td>\n",
              "      <td>0.016968</td>\n",
              "      <td>0.018703</td>\n",
              "      <td>0.003031</td>\n",
              "      <td>0.001726</td>\n",
              "      <td>0.009663</td>\n",
              "      <td>0.014353</td>\n",
              "      <td>0.004346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15152</th>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.003199</td>\n",
              "      <td>0.000973</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.006418</td>\n",
              "      <td>0.011337</td>\n",
              "      <td>0.017698</td>\n",
              "      <td>0.019898</td>\n",
              "      <td>0.001158</td>\n",
              "      <td>0.004187</td>\n",
              "      <td>0.002958</td>\n",
              "      <td>0.007461</td>\n",
              "      <td>0.021452</td>\n",
              "      <td>0.001320</td>\n",
              "      <td>0.001948</td>\n",
              "      <td>0.013476</td>\n",
              "      <td>0.027935</td>\n",
              "      <td>0.003873</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.003544</td>\n",
              "      <td>0.150498</td>\n",
              "      <td>0.011306</td>\n",
              "      <td>0.002513</td>\n",
              "      <td>0.024271</td>\n",
              "      <td>0.011194</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.014263</td>\n",
              "      <td>0.002006</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>0.024921</td>\n",
              "      <td>0.015156</td>\n",
              "      <td>0.059965</td>\n",
              "      <td>0.104966</td>\n",
              "      <td>0.025384</td>\n",
              "      <td>0.004368</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>0.010284</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.050480</td>\n",
              "      <td>0.005101</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.006588</td>\n",
              "      <td>0.045640</td>\n",
              "      <td>0.008847</td>\n",
              "      <td>0.016577</td>\n",
              "      <td>0.030581</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>0.001165</td>\n",
              "      <td>0.013146</td>\n",
              "      <td>0.002519</td>\n",
              "      <td>0.006472</td>\n",
              "      <td>0.016862</td>\n",
              "      <td>0.008962</td>\n",
              "      <td>0.032230</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.014958</td>\n",
              "      <td>0.024519</td>\n",
              "      <td>0.016970</td>\n",
              "      <td>0.009437</td>\n",
              "      <td>0.031180</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.010835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15153</th>\n",
              "      <td>0.012003</td>\n",
              "      <td>0.011296</td>\n",
              "      <td>0.003982</td>\n",
              "      <td>0.007382</td>\n",
              "      <td>0.003259</td>\n",
              "      <td>0.008511</td>\n",
              "      <td>0.014331</td>\n",
              "      <td>0.012176</td>\n",
              "      <td>0.010469</td>\n",
              "      <td>0.005323</td>\n",
              "      <td>0.007106</td>\n",
              "      <td>0.032433</td>\n",
              "      <td>0.018532</td>\n",
              "      <td>0.013591</td>\n",
              "      <td>0.002165</td>\n",
              "      <td>0.003744</td>\n",
              "      <td>0.012677</td>\n",
              "      <td>0.014515</td>\n",
              "      <td>0.003472</td>\n",
              "      <td>0.025335</td>\n",
              "      <td>0.013453</td>\n",
              "      <td>0.025682</td>\n",
              "      <td>0.029097</td>\n",
              "      <td>0.002223</td>\n",
              "      <td>0.025736</td>\n",
              "      <td>0.038660</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>0.021888</td>\n",
              "      <td>0.008814</td>\n",
              "      <td>0.005430</td>\n",
              "      <td>0.015275</td>\n",
              "      <td>0.015150</td>\n",
              "      <td>0.034915</td>\n",
              "      <td>0.066352</td>\n",
              "      <td>0.032225</td>\n",
              "      <td>0.008229</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.013245</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>0.012574</td>\n",
              "      <td>0.039497</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>0.008326</td>\n",
              "      <td>0.012975</td>\n",
              "      <td>0.025496</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>0.021458</td>\n",
              "      <td>0.015476</td>\n",
              "      <td>0.008228</td>\n",
              "      <td>0.005747</td>\n",
              "      <td>0.022150</td>\n",
              "      <td>0.011384</td>\n",
              "      <td>0.018011</td>\n",
              "      <td>0.031658</td>\n",
              "      <td>0.018069</td>\n",
              "      <td>0.031446</td>\n",
              "      <td>0.003657</td>\n",
              "      <td>0.008444</td>\n",
              "      <td>0.010905</td>\n",
              "      <td>0.006160</td>\n",
              "      <td>0.008285</td>\n",
              "      <td>0.011502</td>\n",
              "      <td>0.015991</td>\n",
              "      <td>0.009856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>0.004094</td>\n",
              "      <td>0.010632</td>\n",
              "      <td>0.003330</td>\n",
              "      <td>0.005486</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.024876</td>\n",
              "      <td>0.005206</td>\n",
              "      <td>0.004786</td>\n",
              "      <td>0.009474</td>\n",
              "      <td>0.002383</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>0.003334</td>\n",
              "      <td>0.011988</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.003034</td>\n",
              "      <td>0.002705</td>\n",
              "      <td>0.005484</td>\n",
              "      <td>0.013425</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>0.017130</td>\n",
              "      <td>0.004497</td>\n",
              "      <td>0.050922</td>\n",
              "      <td>0.043420</td>\n",
              "      <td>0.001096</td>\n",
              "      <td>0.015298</td>\n",
              "      <td>0.027695</td>\n",
              "      <td>0.001021</td>\n",
              "      <td>0.046224</td>\n",
              "      <td>0.003730</td>\n",
              "      <td>0.005165</td>\n",
              "      <td>0.015647</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.098992</td>\n",
              "      <td>0.033103</td>\n",
              "      <td>0.104787</td>\n",
              "      <td>0.020771</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.022552</td>\n",
              "      <td>0.003656</td>\n",
              "      <td>0.009487</td>\n",
              "      <td>0.034709</td>\n",
              "      <td>0.007376</td>\n",
              "      <td>0.014867</td>\n",
              "      <td>0.016881</td>\n",
              "      <td>0.012256</td>\n",
              "      <td>0.023525</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.013478</td>\n",
              "      <td>0.000999</td>\n",
              "      <td>0.002442</td>\n",
              "      <td>0.006231</td>\n",
              "      <td>0.005466</td>\n",
              "      <td>0.016896</td>\n",
              "      <td>0.010589</td>\n",
              "      <td>0.006373</td>\n",
              "      <td>0.056237</td>\n",
              "      <td>0.004599</td>\n",
              "      <td>0.006049</td>\n",
              "      <td>0.013898</td>\n",
              "      <td>0.006409</td>\n",
              "      <td>0.002786</td>\n",
              "      <td>0.013068</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.003169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15155 rows × 64 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1caa6ede-c3fd-4187-ab58-e3c272163d56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1caa6ede-c3fd-4187-ab58-e3c272163d56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1caa6ede-c3fd-4187-ab58-e3c272163d56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             12        13        14  ...        73        74        75\n",
              "0      0.003902  0.003144  0.002172  ...  0.039780  0.006316  0.011016\n",
              "1      0.005127  0.013586  0.002661  ...  0.007381  0.015914  0.003997\n",
              "2      0.001358  0.007325  0.002164  ...  0.008010  0.015015  0.001460\n",
              "3      0.000907  0.006270  0.001169  ...  0.013885  0.003157  0.002335\n",
              "4      0.002756  0.012141  0.002344  ...  0.012590  0.010354  0.004409\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "15150  0.003458  0.003411  0.002050  ...  0.028816  0.010205  0.026782\n",
              "15151  0.010864  0.007201  0.008702  ...  0.009663  0.014353  0.004346\n",
              "15152  0.001418  0.003199  0.000973  ...  0.031180  0.008700  0.010835\n",
              "15153  0.012003  0.011296  0.003982  ...  0.011502  0.015991  0.009856\n",
              "15154  0.004094  0.010632  0.003330  ...  0.013068  0.011236  0.003169\n",
              "\n",
              "[15155 rows x 64 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoji_trnx1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxlcU22g_bLd"
      },
      "source": [
        "###### Or read emoji predictions from the saved files with unshuffled trn_df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVKJD-KTgebz"
      },
      "outputs": [],
      "source": [
        "emoji_df1_trn = pd.read_csv(\"emoji_feature_vectors_trn_x1.csv\", encoding=\"utf-8\")\n",
        "emoji_trnx1 =  emoji_df1_trn[emoji_df1_trn.columns[-64:]]\n",
        "emoji_df1_tst = pd.read_csv(\"emoji_feature_vectors_tst_x1.csv\", encoding=\"utf-8\")\n",
        "emoji_tstx1 = emoji_df1_tst[emoji_df1_tst.columns[-64:]]\n",
        "emoji_trnx1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXnGqfzVELrl"
      },
      "source": [
        "##### add the emoji vectors to trn and tst vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASD-UEXBj0wn"
      },
      "outputs": [],
      "source": [
        "# add the emoji vectors to trn and tst vectors\n",
        "trn_x_encoded_with_emoji = hstack((trn_x_encoded1, csr_matrix(emoji_trnx1)))\n",
        "tst_x_encoded_with_emoji = hstack((tst_x_encoded1, csr_matrix(emoji_tstx1)))\n",
        "trn_x_encoded_with_emoji, tst_x_encoded_with_emoji.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJgBDJoYDe6C"
      },
      "source": [
        "### Get labels ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fSegFGQCnwr"
      },
      "outputs": [],
      "source": [
        "trn_y_encoded1 = np.array(trn_y1)\n",
        "tst_y_encoded1 = np.array(tst_y1)\n",
        "tst_y_encoded1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZAf62iKDiHz"
      },
      "source": [
        "### Train svm model without any sementic scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LomswWltdjOX",
        "outputId": "b18d46f2-dcdd-4775-f616-d0da8a0eb8f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1 = svm.SVC(kernel=\"linear\", C=1, gamma=\"scale\")\n",
        "model1.fit(trn_x_encoded1, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MarYTBgzcVu-"
      },
      "outputs": [],
      "source": [
        "pred1 = model1.predict(tst_x_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oDh1ejWzcip",
        "outputId": "7ecefee0-6f25-43f0-d680-3ab1e81d9342"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqHbh-3INXk",
        "outputId": "80e5c370-70b8-4ee8-bcf6-d8bd0425c7a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      1893\n",
            "           1       0.54      0.48      0.51       201\n",
            "\n",
            "    accuracy                           0.91      2094\n",
            "   macro avg       0.74      0.72      0.73      2094\n",
            "weighted avg       0.91      0.91      0.91      2094\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5052631578947369, None)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_sc1 = f1_score(tst_y_encoded1, pred1)\n",
        "cls_report1 = classification_report(tst_y_encoded1, pred1)\n",
        "f1_sc1, print(cls_report1) #0.694 macro, 0.505 binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kddWldneDoPz"
      },
      "source": [
        "### Train svm with sentiment scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR6DXW64d-Kk",
        "outputId": "e0f1862e-1480-4824-abcc-4822493b2302"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_senti = svm.SVC(kernel=\"linear\", C=1, gamma=\"scale\")\n",
        "model_with_senti.fit(trn_x_encoded_with_senti, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yl_uXH0D5qh"
      },
      "outputs": [],
      "source": [
        "pred_with_senti = model_with_senti.predict(tst_x_encoded_with_senti) # should predict encoded matrix or just the text strings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1v0o7C8azO-"
      },
      "outputs": [],
      "source": [
        "f1_sc_with_senti = f1_score(tst_y_encoded1, pred_with_senti)\n",
        "cls_report_senti = classification_report(tst_y_encoded1, pred_with_senti)\n",
        "f1_sc_with_senti, print(cls_report_senti) #0.7076 macro, 0.521 binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guefloT5DsqS"
      },
      "source": [
        "### Train svm model with emoji scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U34cieNleRZ"
      },
      "outputs": [],
      "source": [
        "model_with_emoji = svm.SVC(kernel=\"linear\", C=1, gamma=\"scale\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9C0CPqFFUOk"
      },
      "outputs": [],
      "source": [
        "model_with_emoji.fit(trn_x_encoded_with_emoji, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sjWw68Ylwah"
      },
      "outputs": [],
      "source": [
        "pred_with_emoji = model_with_emoji.predict(tst_x_encoded_with_emoji)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryS3cQqRl8-c"
      },
      "outputs": [],
      "source": [
        "f1_sc_with_emoji =  f1_score(tst_y_encoded1, pred_with_emoji)\n",
        "cls_report_emoji = classification_report(tst_y_encoded1, pred_with_emoji)\n",
        "f1_sc_with_emoji, print(cls_report_emoji) #0.4986 binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNUDnSHGBQnA"
      },
      "source": [
        "## Ensemble Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhgu78BWBUbz",
        "outputId": "083a20e8-446f-4439-92d0-1cfc69765870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install vecstack\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from vecstack import stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu4BkiAaA0BE"
      },
      "source": [
        "##### Stacking models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24gYRfsoDNsB"
      },
      "outputs": [],
      "source": [
        "## models for stacking\n",
        "base1 = RandomForestClassifier(random_state=0, max_features='auto', max_depth=3)\n",
        "base2 = LogisticRegression(solver='liblinear', max_iter=200)\n",
        "pipeline = make_pipeline(StandardScaler(with_mean=False),\n",
        "                           svm.SVC(C=1.0, kernel='linear'))\n",
        "svc = svm.SVC(C=1.0, kernel='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYG_X3B3EY73"
      },
      "source": [
        "##### stack with both emoji and senti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ATs4MvMKjSk"
      },
      "outputs": [],
      "source": [
        "# stacking with emoji and senti\n",
        "# get the prediction for both trn_x and tst_x\n",
        "def ensemble_stacking_both_fit(trn_x, trn_y, tst_x):\n",
        "  trn_x_s, tst_x_s = stacking([base1, base3], trn_x, trn_y, tst_x, stratified=True,\n",
        "                              regression=False, n_folds=5,\n",
        "                              shuffle=True, verbose=2)\n",
        "  print(tst_x_s.shape)\n",
        "  # stack the prediciton from emoji to the trn_x_s and tst_x_s\n",
        "  trn_x_s = np.hstack((np.array(emoji_trnx1), trn_x_s))\n",
        "  tst_x_s = np.hstack((np.array(emoji_tstx1), tst_x_s))\n",
        "  meta_model = base2\n",
        "  meta_model.fit(trn_x_s, trn_y)\n",
        "  pred = meta_model.predict(tst_x_s)\n",
        "  return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg1owllITXuv",
        "outputId": "6e5f79cd-7178-4172-fd04-2d5bfe1feb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [2]\n",
            "\n",
            "model  0:     [RandomForestClassifier]\n",
            "    fold  0:  [0.74331904]\n",
            "    fold  1:  [0.75882547]\n",
            "    fold  2:  [0.74826790]\n",
            "    fold  3:  [0.74661828]\n",
            "    fold  4:  [0.78686902]\n",
            "    ----\n",
            "    MEAN:     [0.75677994] + [0.01591507]\n",
            "    FULL:     [0.75677994]\n",
            "\n",
            "model  1:     [SVC]\n",
            "    fold  0:  [0.98152425]\n",
            "    fold  1:  [0.98449357]\n",
            "    fold  2:  [0.98152425]\n",
            "    fold  3:  [0.98317387]\n",
            "    fold  4:  [0.98317387]\n",
            "    ----\n",
            "    MEAN:     [0.98277796] + [0.00113140]\n",
            "    FULL:     [0.98277796]\n",
            "\n",
            "(15155, 2)\n"
          ]
        }
      ],
      "source": [
        "pred_stacking_both = ensemble_stacking_both_fit(trn_x_encoded_with_senti, \n",
        "                                               trn_y_encoded1,\n",
        "                                               tst_x_encoded_with_senti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_tbl3p4aC8D",
        "outputId": "fd93f032-6235-41ce-e3ca-ffbad5fbff29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95      1893\n",
            "           1       0.54      0.50      0.52       201\n",
            "\n",
            "    accuracy                           0.91      2094\n",
            "   macro avg       0.74      0.73      0.73      2094\n",
            "weighted avg       0.91      0.91      0.91      2094\n",
            " 0.5181347150259068\n"
          ]
        }
      ],
      "source": [
        "f1_stacking_both = f1_score(tst_y_encoded1, pred_stacking_both)\n",
        "cls_report_stacking_both = classification_report(tst_y_encoded1, pred_stacking_both)\n",
        "print(cls_report_stacking_both, f1_stacking_both)\n",
        "# label:1       0.54      0.50      0.52;  binary f1: 0.518   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt4rqV04BfVz"
      },
      "source": [
        "##### Stack the predictions from 5 nn models on top of emoji and senti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRKEqoItKa4g"
      },
      "outputs": [],
      "source": [
        "### read the predictions of nn from the files nn5_preds\n",
        "tst_nn_preds = pd.read_csv(\"5nn_predictions.csv\", encoding=\"utf-8\")\n",
        "tst_nn_preds = np.array(tst_nn_preds)\n",
        "trn_nn_preds = pd.read_csv(\"trn_5nn_predictions.csv\", encoding=\"utf-8\")\n",
        "trn_nn_preds = np.array(trn_nn_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1kJygmj27JX",
        "outputId": "c75b7287-6e72-4e51-f60b-124ba77e5720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 5.4094577e-01, 2.9859180e-01, 2.8656210e-01,\n",
              "        2.3361695e-01, 2.4493778e-01],\n",
              "       [1.0000000e+00, 5.4094577e-01, 5.7595766e-01, 6.0827285e-01,\n",
              "        5.7385770e-01, 5.7605040e-01],\n",
              "       [2.0000000e+00, 5.4094577e-01, 4.4539046e-01, 4.6011204e-01,\n",
              "        3.2503462e-01, 3.7752926e-01],\n",
              "       ...,\n",
              "       [1.5152000e+04, 5.4094577e-01, 6.1489700e-01, 6.3552010e-01,\n",
              "        6.0550475e-01, 6.2028307e-01],\n",
              "       [1.5153000e+04, 5.4094577e-01, 3.0497026e-01, 4.0300885e-01,\n",
              "        3.1272823e-01, 9.6421397e-01],\n",
              "       [1.5154000e+04, 9.9765170e-01, 6.1489700e-01, 6.3656425e-01,\n",
              "        5.7576823e-01, 6.2028307e-01]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trn_nn_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2luNye70DZl2"
      },
      "outputs": [],
      "source": [
        "# stacking with emoji and senti and 5 nn models predictions\n",
        "# get the predictions for both trn_x and tst_x\n",
        "def ensemble_stacking_nn_fit(trn_x, trn_y, tst_x):\n",
        "  trn_x_s, tst_x_s = stacking([base1, svc], trn_x, trn_y, tst_x, stratified=True,\n",
        "                              regression=False, n_folds=5,\n",
        "                              shuffle=True, verbose=2)\n",
        "  print(tst_x_s.shape)\n",
        "  # stack the senti scores \n",
        "  trn_x_s = np.hstack((sc_trn1, trn_x_s))\n",
        "  tst_x_s = np.hstack((sc_tst1, tst_x_s))\n",
        "  # stack the prediciton from emoji preds to the trn_x_s and tst_x_s\n",
        "  trn_x_s = np.hstack((np.array(emoji_trnx1), trn_x_s))\n",
        "  tst_x_s = np.hstack((np.array(emoji_tstx1), tst_x_s))\n",
        "  # stack the predictions from the 5nn models to the trn_x_s and tst_x_s\n",
        "  #trn_x_s = np.hstack((trn_x_s, trn_nn_preds))\n",
        "  #tst_x_s = np.hstack((tst_x_s, tst_nn_preds))\n",
        "  # scale the data\n",
        "  #ssl = StandardScaler()\n",
        "  #trn_x_s = ssl.fit_transform(trn_x_s)\n",
        "  #tst_x_s = ssl.transform(tst_x_s)\n",
        "  print(\"tst_x_s:{}\".format(tst_x_s))\n",
        "  meta_model = base2\n",
        "  meta_model.fit(trn_x_s, trn_y)\n",
        "  pred = meta_model.predict(tst_x_s)\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh0S67EC3Quq",
        "outputId": "e6daad74-91d2-4866-e942-da83a5cddded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [2]\n",
            "\n",
            "model  0:     [RandomForestClassifier]\n",
            "    fold  0:  [0.83767733]\n",
            "    fold  1:  [0.82612999]\n",
            "    fold  2:  [0.84295612]\n",
            "    fold  3:  [0.84757506]\n",
            "    fold  4:  [0.84460574]\n",
            "    ----\n",
            "    MEAN:     [0.83978885] + [0.00754827]\n",
            "    FULL:     [0.83978885]\n",
            "\n",
            "model  1:     [SVC]\n"
          ]
        }
      ],
      "source": [
        "pred_stacking_nn = ensemble_stacking_nn_fit(trn_x_encoded1, \n",
        "                                               trn_y_encoded1,\n",
        "                                               tst_x_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtPrE39g3pJG"
      },
      "outputs": [],
      "source": [
        "f1_stacking_nn = f1_score(tst_y_encoded1, pred_stacking_nn)\n",
        "cls_report_stacking_nn = classification_report(tst_y_encoded1, pred_stacking_nn)\n",
        "print(cls_report_stacking_nn, f1_stacking_nn) #1       0.54      0.50      0.52  , f1_binary: 0.5206 with scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAFf16Gy-A5f",
        "outputId": "99402e92-8027-4737-decf-8e2e0c763a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 0 0 1] 2094\n"
          ]
        }
      ],
      "source": [
        "print(pred_stacking_nn, len(pred_stacking_nn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIJJamRcCXMM"
      },
      "source": [
        "##### stack either with senti or emoji to the data in the beginning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6NWv9a3L2S1"
      },
      "outputs": [],
      "source": [
        "# only with either emoji or senti\n",
        "model_stacking = StackingClassifier(estimators=[('rf', base1), ('svc', base3)], \n",
        "                                    final_estimator=base2, passthrough=True)\n",
        "model_stacking.fit(trn_x_encoded_with_senti, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhxfHb0qYHb6",
        "outputId": "e57f02bf-ad54-40b8-fc5c-7ad3f06ae9a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96      1893\n",
            "           1       0.68      0.26      0.37       201\n",
            "\n",
            "    accuracy                           0.92      2094\n",
            "   macro avg       0.80      0.62      0.66      2094\n",
            "weighted avg       0.90      0.92      0.90      2094\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.37410071942446044, None)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_stk = model_stacking.predict(tst_x_encoded_with_senti)\n",
        "f1_stk = f1_score(tst_y_encoded1, pred_stk)\n",
        "cls_report_stk = classification_report(tst_y_encoded1, pred_stk)\n",
        "f1_stk, print(cls_report_stk) #0.37 emoji with passthrough=True,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ldmxwi7Cu4H"
      },
      "source": [
        "#### bagging or boosting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w84ax-HrCy75"
      },
      "source": [
        "##### bagging models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRz05XZbBqyd"
      },
      "outputs": [],
      "source": [
        "def ensemble_model(classifier_name, base_estimator=None, estimator_n=10):\n",
        "  if classifier_name == \"bagging\" and base_estimator is not None:\n",
        "    model = BaggingClassifier(base_estimator, n_estimators=estimator_n,\n",
        "                              max_samples=0.5, max_features=1)\n",
        "  elif classifier_name == \"boosting\":\n",
        "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01)\n",
        "  else:\n",
        "    print(\"The classifier names can only be 'bagging' or 'boosting'.\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsUqKOvJGBf9",
        "outputId": "5073deab-e2d2-4886-8594-6dde37cc081a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=SVC(kernel='linear'), max_features=1,\n",
              "                  max_samples=0.5)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# bagging ensemble \n",
        "\n",
        "# with senti\n",
        "base_estm = svm.SVC(C=1.0, kernel='linear')\n",
        "model_bagging = ensemble_model(\"bagging\", base_estm)\n",
        "model_bagging.fit(trn_x_encoded_with_senti, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0a6ELHFGOIJ",
        "outputId": "d54c6b7b-9391-4f80-9045-e6e614a2aaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1893\n",
            "           1       0.10      1.00      0.18       201\n",
            "\n",
            "    accuracy                           0.10      2094\n",
            "   macro avg       0.05      0.50      0.09      2094\n",
            "weighted avg       0.01      0.10      0.02      2094\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.17516339869281047, None)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_bagging = model_bagging.predict(tst_x_encoded_with_senti)\n",
        "f1_bag = f1_score(tst_y_encoded1, pred_bagging, average='binary')\n",
        "cls_report_bag = classification_report(tst_y_encoded1, pred_bagging)\n",
        "f1_bag, print(cls_report_bag) #with senti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1LiKQlxSnhc",
        "outputId": "d20bd7da-fe06-4dce-bafc-18576ee8b93b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaggingClassifier(base_estimator=SVC(kernel='linear'), max_features=1,\n",
              "                  max_samples=0.5, n_estimators=20)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# with emoji\n",
        "base_estm = svm.SVC(C=1.0, kernel='linear')\n",
        "model_bagging = ensemble_model(\"bagging\", base_estm, estimator_n=20)\n",
        "model_bagging.fit(trn_x_encoded_with_emoji, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tViCNj9RJzn_",
        "outputId": "1d4ebcc6-8603-4e8d-e572-fc8e75652602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      1893\n",
            "           1       0.00      0.00      0.00       201\n",
            "\n",
            "    accuracy                           0.90      2094\n",
            "   macro avg       0.45      0.50      0.47      2094\n",
            "weighted avg       0.82      0.90      0.86      2094\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.0, None)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_bagging = model_bagging.predict(tst_x_encoded_with_emoji)\n",
        "f1_bag = f1_score(tst_y_encoded1, pred_bagging, average='binary')\n",
        "cls_report_bag = classification_report(tst_y_encoded1, pred_bagging)\n",
        "f1_bag, print(cls_report_bag) #with emoji 0.49 with feature_n 0.5, set feature_n to 1.0 gets 0.515"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v524xbr3C3MV"
      },
      "source": [
        "##### boosting models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAJR5bcGGnck",
        "outputId": "302d09dd-5f5e-43c6-e3ff-d328b80ab3b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier()"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# boosting ensemble\n",
        "model_boosting = ensemble_model(\"boosting\")\n",
        "model_boosting.fit(trn_x_encoded_with_emoji, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTkhbmqbHKiS",
        "outputId": "ad008990-bb06-45e4-b1f7-b4f64dbbcc6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 1 ... 0 0 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      1893\n",
            "           1       0.41      0.28      0.34       201\n",
            "\n",
            "    accuracy                           0.89      2094\n",
            "   macro avg       0.67      0.62      0.64      2094\n",
            "weighted avg       0.88      0.89      0.88      2094\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pred_boosting = model_boosting.predict(tst_x_encoded_with_emoji)\n",
        "print(pred_boosting)\n",
        "cls_report_bst = classification_report(tst_y_encoded1, pred_boosting)\n",
        "print(cls_report_bst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOLdBz7raRMJ"
      },
      "source": [
        "# **Fine-Tuning** with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnRW2C71uTmz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcmrQkdSstTv"
      },
      "outputs": [],
      "source": [
        "\n",
        "parameters = {'kernel': ('linear', 'rbf'), 'C':[0.01, 0.1, 1, 10, 100], 'gamma':('scale', 'auto'), \n",
        "              'class_weight': ['balanced']}\n",
        "svc = svm.SVC()\n",
        "gs = GridSearchCV(svc, parameters)\n",
        "gs.fit(trn_x_encoded_with_senti, trn_y_encoded1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vADGPlGyZ5pF"
      },
      "outputs": [],
      "source": [
        "gs.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a3hkIcnzdlJ"
      },
      "outputs": [],
      "source": [
        "gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsO3NoUHaCzJ"
      },
      "outputs": [],
      "source": [
        "pred_tuned = gs.predict(tst_x_encoded_with_senti) \n",
        "f1_sc_tuned = f1_score(tst_y_encoded1, pred_tuned, average=\"binary\")\n",
        "cls_report_tuned = classification_report(tst_y_encoded1, pred_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwRjJMvfcmf8"
      },
      "outputs": [],
      "source": [
        "f1_sc_tuned, print(cls_report_tuned)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3_ah-fx6ias1",
        "hOLdBz7raRMJ"
      ],
      "name": "pcl_linearmodel_with_augmenteddata.ipynb",
      "provenance": [],
      "mount_file_id": "1pmB_C7TfG7WO8S7xsgcC3v4urZpOv1NC",
      "authorship_tag": "ABX9TyNOo5T0qW8w8p70TrxrYbDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}